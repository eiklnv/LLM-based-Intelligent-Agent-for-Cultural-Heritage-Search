"""
RelicSeekæ™ºèƒ½ä½“å®ç°
"""
import json
import logging
from typing import Dict, List, Any, Optional
from langchain.agents import AgentExecutor, create_react_agent
from langchain.memory import ConversationBufferWindowMemory
from langchain_openai import ChatOpenAI
from langchain.prompts import PromptTemplate
from langchain.schema import BaseMessage, HumanMessage, SystemMessage

from ..config.settings import Settings, EngineConfig
from ..config.prompt_manager import PromptManager
from .tools import RelicSearchToolkit


class RelicSeekAgent:
    """RelicSeekæ–‡ç‰©æœç´¢æ™ºèƒ½ä½“"""
    
    def __init__(self, settings: Settings):
        """
        åˆå§‹åŒ–æ™ºèƒ½ä½“
        
        Args:
            settings: ç³»ç»Ÿè®¾ç½®
        """
        self.settings = settings
        self.engine_config = settings.load_engine_config()
        self.prompt_manager = PromptManager()
        
        # è®¾ç½®æ—¥å¿—
        self.logger = logging.getLogger(__name__)
        
        # åˆå§‹åŒ–ç»„ä»¶
        self._setup_llm()
        self._setup_memory()
        self._setup_tools()
        self._setup_agent()
    
    def _setup_llm(self):
        """è®¾ç½®å¤§è¯­è¨€æ¨¡å‹"""
        model_config = self.engine_config.model
        
        # è·å–APIå¯†é’¥
        api_key = self.settings.get_openai_api_key()
        
        # å¯¹äºè‡ªå®šä¹‰æ¨¡å‹æœåŠ¡å™¨ï¼Œå…è®¸ä½¿ç”¨EMPTYæˆ–å…¶ä»–å ä½ç¬¦
        # åªæœ‰åœ¨æ²¡æœ‰é…ç½®API base URLä¸”APIå¯†é’¥ä¸ºç©ºæ—¶æ‰æŠ¥é”™
        api_base = self.settings.get_openai_api_base()
        if not api_base and (not api_key or api_key == "EMPTY"):
            raise ValueError("è¯·è®¾ç½®OPENAI_API_KEYç¯å¢ƒå˜é‡æˆ–é…ç½®APIå¯†é’¥")
        
        # å¦‚æœä½¿ç”¨è‡ªå®šä¹‰API baseï¼Œå°†EMPTYæ›¿æ¢ä¸ºæœ‰æ•ˆçš„å ä½ç¬¦
        if api_base and (not api_key or api_key == "EMPTY"):
            api_key = "sk-custom-api-key-placeholder"
        
        # æ„å»ºLLMå‚æ•°
        llm_kwargs = {
            'model': model_config.model_name,
            'temperature': model_config.temperature,
            'max_tokens': model_config.max_tokens,
            'timeout': model_config.timeout,
            'openai_api_key': api_key
        }
        
        # å¦‚æœé…ç½®äº†è‡ªå®šä¹‰API base URLï¼Œåˆ™æ·»åŠ 
        if api_base:
            llm_kwargs['base_url'] = api_base
        
        self.llm = ChatOpenAI(**llm_kwargs)
    
    def _setup_memory(self):
        """è®¾ç½®è®°å¿†ç®¡ç†"""
        agent_config = self.engine_config.agent
        
        if agent_config.memory_type == "buffer_window":
            self.memory = ConversationBufferWindowMemory(
                k=agent_config.memory_window_size,
                return_messages=True,
                memory_key="chat_history"
            )
        else:
            self.memory = ConversationBufferWindowMemory(
                k=10,
                return_messages=True,
                memory_key="chat_history"
            )
    
    def _setup_tools(self):
        """è®¾ç½®å·¥å…·"""
        searxng_config = self.engine_config.searxng.dict()
        # æ·»åŠ æœç´¢é…ç½®å‚æ•°
        searxng_config['search_config'] = self.engine_config.search.dict()
        self.search_toolkit = RelicSearchToolkit(searxng_config)
        self.tools = self.search_toolkit.get_langchain_tools()
    
    def _setup_agent(self):
        """è®¾ç½®æ™ºèƒ½ä½“"""
        # è·å–ç³»ç»Ÿprompt
        system_prompt = self.prompt_manager.get_system_prompt("agent_system")
        
        # åˆ›å»ºReAct promptæ¨¡æ¿
        react_prompt = PromptTemplate.from_template(
            f"""{system_prompt}

ä½ æœ‰æƒè®¿é—®ä»¥ä¸‹å·¥å…·:

{{tools}}

ä½¿ç”¨ä»¥ä¸‹æ ¼å¼:

Question: ç”¨æˆ·çš„é—®é¢˜
Thought: æˆ‘éœ€è¦æ€è€ƒåº”è¯¥åšä»€ä¹ˆ
Action: è¦é‡‡å–çš„è¡ŒåŠ¨ï¼Œåº”è¯¥æ˜¯[{{tool_names}}]ä¸­çš„ä¸€ä¸ª
Action Input: è¡ŒåŠ¨çš„è¾“å…¥
Observation: è¡ŒåŠ¨çš„ç»“æœ
... (è¿™ä¸ªThought/Action/Action Input/Observationå¯ä»¥é‡å¤Næ¬¡)
Thought: æˆ‘ç°åœ¨çŸ¥é“æœ€ç»ˆç­”æ¡ˆäº†
Final Answer: å¯¹åŸå§‹é—®é¢˜çš„æœ€ç»ˆç­”æ¡ˆ

å¼€å§‹!

Previous conversation history:
{{chat_history}}

Question: {{input}}
{{agent_scratchpad}}"""
        )
        
        # åˆ›å»ºReActæ™ºèƒ½ä½“
        self.agent = create_react_agent(
            llm=self.llm,
            tools=self.tools,
            prompt=react_prompt
        )
        
        # åˆ›å»ºæ™ºèƒ½ä½“æ‰§è¡Œå™¨
        agent_config = self.engine_config.agent
        self.agent_executor = AgentExecutor(
            agent=self.agent,
            tools=self.tools,
            memory=self.memory,
            max_iterations=agent_config.max_iterations,
            max_execution_time=agent_config.max_execution_time,
            early_stopping_method=agent_config.early_stopping_method,
            verbose=True,
            handle_parsing_errors=True
        )
    
    def search(self, query: str, context: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """
        æ‰§è¡Œæ–‡ç‰©æœç´¢
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            context: æœç´¢ä¸Šä¸‹æ–‡
            
        Returns:
            æœç´¢ç»“æœ
        """
        try:
            # æ‰“å°æ™ºèƒ½ä½“æœç´¢è°ƒè¯•ä¿¡æ¯
            self.logger.info("ğŸ¤–" + "=" * 58)
            self.logger.info("ğŸ¤– RelicSeekæ™ºèƒ½ä½“å¼€å§‹å¤„ç†æŸ¥è¯¢")
            self.logger.info(f"ğŸ¤– ğŸ“ ç”¨æˆ·æŸ¥è¯¢: {query}")
            if context:
                self.logger.info(f"ğŸ¤– ğŸ” æœç´¢ä¸Šä¸‹æ–‡: {context}")
            self.logger.info("ğŸ¤–" + "=" * 58)
            
            # åˆ†ææŸ¥è¯¢
            self.logger.info("ğŸ¤– ğŸ” æ­¥éª¤1: åˆ†æç”¨æˆ·æŸ¥è¯¢")
            analysis_result = self._analyze_query(query)
            self.logger.info(f"ğŸ¤– âœ… æŸ¥è¯¢åˆ†æå®Œæˆ")
            if 'analysis_text' in analysis_result:
                self.logger.info(f"ğŸ¤– ğŸ“‹ åˆ†æç»“æœ: {analysis_result['analysis_text'][:200]}...")
            
            # åˆ¶å®šæœç´¢ç­–ç•¥
            self.logger.info("ğŸ¤– ğŸ¯ æ­¥éª¤2: åˆ¶å®šæœç´¢ç­–ç•¥")
            strategy = self._plan_search_strategy(analysis_result)
            self.logger.info(f"ğŸ¤– âœ… æœç´¢ç­–ç•¥åˆ¶å®šå®Œæˆ")
            if 'strategy_text' in strategy:
                self.logger.info(f"ğŸ¤– ğŸ“‹ ç­–ç•¥å†…å®¹: {strategy['strategy_text'][:200]}...")
            if 'keywords' in strategy:
                self.logger.info(f"ğŸ¤– ğŸ”‘ å…³é”®è¯: {strategy['keywords']}")
            
            # æ‰§è¡Œæœç´¢
            self.logger.info("ğŸ¤– ğŸ” æ­¥éª¤3: æ‰§è¡Œæœç´¢")
            search_results = self._execute_search(query, strategy)
            self.logger.info(f"ğŸ¤– âœ… æœç´¢æ‰§è¡Œå®Œæˆ")
            if 'agent_output' in search_results:
                self.logger.info(f"ğŸ¤– ğŸ“‹ æ™ºèƒ½ä½“è¾“å‡º: {search_results['agent_output'][:200]}...")
            
            # éªŒè¯å’Œåæ€
            self.logger.info("ğŸ¤– ğŸ” æ­¥éª¤4: éªŒè¯å’Œåæ€æœç´¢ç»“æœ")
            validated_results = self._validate_and_reflect(search_results, query)
            self.logger.info(f"ğŸ¤– âœ… éªŒè¯å’Œåæ€å®Œæˆ")
            if 'quality_score' in validated_results:
                self.logger.info(f"ğŸ¤– â­ è´¨é‡è¯„åˆ†: {validated_results['quality_score']}")
            if 'confidence' in validated_results:
                self.logger.info(f"ğŸ¤– ğŸ¯ ç½®ä¿¡åº¦: {validated_results['confidence']}")
            
            # ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
            self.logger.info("ğŸ¤– ğŸ“ æ­¥éª¤5: ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š")
            final_report = self._generate_final_report(validated_results, query)
            self.logger.info(f"ğŸ¤– âœ… æœ€ç»ˆæŠ¥å‘Šç”Ÿæˆå®Œæˆ")
            self.logger.info(f"ğŸ¤– ğŸ“‹ æŠ¥å‘Šé•¿åº¦: {len(final_report)} å­—ç¬¦")
            
            result = {
                'success': True,
                'query': query,
                'analysis': analysis_result,
                'strategy': strategy,
                'results': validated_results,
                'report': final_report,
                'metadata': {
                    'timestamp': self._get_current_timestamp(),
                    'iterations': getattr(self.agent_executor, 'iterations', 0)
                }
            }
            
            self.logger.info("ğŸ¤– ğŸ‰ æ™ºèƒ½ä½“æœç´¢å¤„ç†å®Œæˆ")
            self.logger.info("ğŸ¤–" + "=" * 58)
            
            return result
            
        except Exception as e:
            self.logger.error(f"ğŸ¤– âŒ æœç´¢è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
            return {
                'success': False,
                'error': str(e),
                'query': query
            }
    
    def _analyze_query(self, query: str) -> Dict[str, Any]:
        """åˆ†æç”¨æˆ·æŸ¥è¯¢"""
        try:
            prompt = self.prompt_manager.get_prompt("query_analysis", user_query=query)
            
            response = self.llm.invoke([
                SystemMessage(content=self.prompt_manager.get_system_prompt("search_expert")),
                HumanMessage(content=prompt)
            ])
            
            # ç®€å•è§£æå“åº”ï¼ˆå®é™…åº”ç”¨ä¸­å¯èƒ½éœ€è¦æ›´å¤æ‚çš„è§£æï¼‰
            return {
                'analysis_text': response.content,
                'complexity': self._extract_complexity(response.content),
                'entities': self._extract_entities(response.content),
                'query_type': self._extract_query_type(response.content)
            }
        except Exception as e:
            self.logger.error(f"æŸ¥è¯¢åˆ†æå¤±è´¥: {str(e)}")
            return {'error': str(e)}
    
    def _plan_search_strategy(self, analysis_result: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ¶å®šæœç´¢ç­–ç•¥"""
        try:
            prompt = self.prompt_manager.get_prompt(
                "strategy_planning", 
                analysis_result=json.dumps(analysis_result, ensure_ascii=False)
            )
            
            response = self.llm.invoke([
                SystemMessage(content=self.prompt_manager.get_system_prompt("search_expert")),
                HumanMessage(content=prompt)
            ])
            
            return {
                'strategy_text': response.content,
                'keywords': self._extract_keywords(response.content),
                'search_steps': self._extract_search_steps(response.content)
            }
        except Exception as e:
            self.logger.error(f"ç­–ç•¥åˆ¶å®šå¤±è´¥: {str(e)}")
            return {'error': str(e)}
    
    def _execute_search(self, query: str, strategy: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œæœç´¢"""
        try:
            # ä½¿ç”¨æ™ºèƒ½ä½“æ‰§è¡Œå™¨è¿›è¡Œæœç´¢
            result = self.agent_executor.invoke({
                'input': f"è¯·æ ¹æ®ä»¥ä¸‹æœç´¢ç­–ç•¥ä¸ºç”¨æˆ·æŸ¥è¯¢'{query}'å¯»æ‰¾ç›¸å…³çš„æ–‡ç‰©ä¿¡æ¯ï¼š\n{strategy.get('strategy_text', '')}"
            })
            
            return {
                'agent_output': result.get('output', ''),
                'intermediate_steps': result.get('intermediate_steps', []),
                'final_answer': result.get('output', '')
            }
        except Exception as e:
            self.logger.error(f"æœç´¢æ‰§è¡Œå¤±è´¥: {str(e)}")
            return {'error': str(e)}
    
    def _validate_and_reflect(self, search_results: Dict[str, Any], 
                             original_query: str) -> Dict[str, Any]:
        """éªŒè¯å’Œåæ€æœç´¢ç»“æœ"""
        try:
            prompt = self.prompt_manager.get_prompt(
                "reflection",
                current_results=json.dumps(search_results, ensure_ascii=False),
                original_query=original_query
            )
            
            response = self.llm.invoke([
                SystemMessage(content=self.prompt_manager.get_system_prompt("search_expert")),
                HumanMessage(content=prompt)
            ])
            
            # è·å–è´¨é‡è¯„ä¼°
            quality_assessment = self._assess_quality(search_results)
            
            return {
                'validated_results': search_results,
                'reflection': response.content,
                'quality_score': quality_assessment.get('score', 0),
                'confidence': quality_assessment.get('confidence', 'low'),
                'recommendations': self._extract_recommendations(response.content)
            }
        except Exception as e:
            self.logger.error(f"éªŒè¯å’Œåæ€å¤±è´¥: {str(e)}")
            return search_results
    
    def _assess_quality(self, results: Dict[str, Any]) -> Dict[str, Any]:
        """è¯„ä¼°ç»“æœè´¨é‡"""
        try:
            prompt = self.prompt_manager.get_prompt(
                "quality_assessment",
                artifact_info=json.dumps(results, ensure_ascii=False),
                source_info="æœç´¢ç»“æœé›†"
            )
            
            response = self.llm.invoke([
                SystemMessage(content=self.prompt_manager.get_system_prompt("search_expert")),
                HumanMessage(content=prompt)
            ])
            
            return {
                'score': self._extract_quality_score(response.content),
                'confidence': self._extract_confidence(response.content),
                'assessment_text': response.content
            }
        except Exception as e:
            self.logger.error(f"è´¨é‡è¯„ä¼°å¤±è´¥: {str(e)}")
            return {'score': 0, 'confidence': 'low'}
    
    def _generate_final_report(self, validated_results: Dict[str, Any], 
                              query: str) -> str:
        """ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š"""
        try:
            prompt = self.prompt_manager.get_prompt(
                "final_summary",
                artifact_data=json.dumps(validated_results, ensure_ascii=False),
                search_context=query
            )
            
            response = self.llm.invoke([
                SystemMessage(content=self.prompt_manager.get_system_prompt("search_expert")),
                HumanMessage(content=prompt)
            ])
            
            return response.content
        except Exception as e:
            self.logger.error(f"æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {str(e)}")
            return f"æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {str(e)}"
    
    # è¾…åŠ©æ–¹æ³•ç”¨äºä»LLMå“åº”ä¸­æå–ç»“æ„åŒ–ä¿¡æ¯
    def _extract_complexity(self, text: str) -> str:
        """ä»åˆ†ææ–‡æœ¬ä¸­æå–å¤æ‚åº¦"""
        if "å¤æ‚åº¦ï¼š" in text:
            line = [l for l in text.split('\n') if "å¤æ‚åº¦ï¼š" in l][0]
            return line.split("å¤æ‚åº¦ï¼š")[1].strip()
        return "ä¸­ç­‰"
    
    def _extract_entities(self, text: str) -> List[str]:
        """ä»åˆ†ææ–‡æœ¬ä¸­æå–å®ä½“"""
        entities = []
        if "å…³é”®å®ä½“ï¼š" in text:
            line = [l for l in text.split('\n') if "å…³é”®å®ä½“ï¼š" in l][0]
            entities_text = line.split("å…³é”®å®ä½“ï¼š")[1].strip()
            entities = [e.strip() for e in entities_text.split(',') if e.strip()]
        return entities
    
    def _extract_query_type(self, text: str) -> str:
        """ä»åˆ†ææ–‡æœ¬ä¸­æå–æŸ¥è¯¢ç±»å‹"""
        if "æŸ¥è¯¢ç±»å‹ï¼š" in text:
            line = [l for l in text.split('\n') if "æŸ¥è¯¢ç±»å‹ï¼š" in l][0]
            return line.split("æŸ¥è¯¢ç±»å‹ï¼š")[1].strip()
        return "å±æ€§æœç´¢"
    
    def _extract_keywords(self, text: str) -> List[str]:
        """ä»ç­–ç•¥æ–‡æœ¬ä¸­æå–å…³é”®è¯"""
        keywords = []
        if "ä¸»è¦å…³é”®è¯ï¼š" in text:
            line = [l for l in text.split('\n') if "ä¸»è¦å…³é”®è¯ï¼š" in l][0]
            keywords_text = line.split("ä¸»è¦å…³é”®è¯ï¼š")[1].strip()
            keywords = [k.strip() for k in keywords_text.split(',') if k.strip()]
        return keywords
    
    def _extract_search_steps(self, text: str) -> List[str]:
        """ä»ç­–ç•¥æ–‡æœ¬ä¸­æå–æœç´¢æ­¥éª¤"""
        steps = []
        lines = text.split('\n')
        for line in lines:
            if line.strip().startswith('æ­¥éª¤'):
                steps.append(line.strip())
        return steps
    
    def _extract_quality_score(self, text: str) -> float:
        """ä»è´¨é‡è¯„ä¼°æ–‡æœ¬ä¸­æå–è¯„åˆ†"""
        if "ç»¼åˆè¯„åˆ†ï¼š" in text:
            line = [l for l in text.split('\n') if "ç»¼åˆè¯„åˆ†ï¼š" in l][0]
            score_text = line.split("ç»¼åˆè¯„åˆ†ï¼š")[1].strip()
            try:
                return float(score_text.split('/')[0])
            except:
                pass
        return 3.0
    
    def _extract_confidence(self, text: str) -> str:
        """ä»è´¨é‡è¯„ä¼°æ–‡æœ¬ä¸­æå–ç½®ä¿¡åº¦"""
        if "ç½®ä¿¡åº¦ï¼š" in text:
            line = [l for l in text.split('\n') if "ç½®ä¿¡åº¦ï¼š" in l][0]
            return line.split("ç½®ä¿¡åº¦ï¼š")[1].strip()
        return "ä¸­"
    
    def _extract_recommendations(self, text: str) -> List[str]:
        """ä»åæ€æ–‡æœ¬ä¸­æå–å»ºè®®"""
        recommendations = []
        if "æ”¹è¿›å»ºè®®ï¼š" in text:
            lines = text.split('\n')
            start_idx = -1
            for i, line in enumerate(lines):
                if "æ”¹è¿›å»ºè®®ï¼š" in line:
                    start_idx = i
                    break
            
            if start_idx >= 0:
                for line in lines[start_idx:]:
                    if line.strip().startswith('-') or line.strip().startswith('â€¢'):
                        recommendations.append(line.strip())
        
        return recommendations
    
    def _get_current_timestamp(self) -> str:
        """è·å–å½“å‰æ—¶é—´æˆ³"""
        from datetime import datetime
        return datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    def get_conversation_history(self) -> List[BaseMessage]:
        """è·å–å¯¹è¯å†å²"""
        if hasattr(self.memory, 'chat_memory'):
            return self.memory.chat_memory.messages
        return []
    
    def clear_memory(self):
        """æ¸…é™¤è®°å¿†"""
        if hasattr(self.memory, 'clear'):
            self.memory.clear()
